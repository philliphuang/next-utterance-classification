{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "The majority of our implementations for for next utterance classification including:\n",
    "1. completely random predictor\n",
    "2. TF-IDF\n",
    "3. word2vec (with averaging)\n",
    "4. doc2vec\n",
    "5. LDA\n",
    "6. K-means with Gaussian Naive Bayes Classifier\n",
    "\n",
    "Check the report for the locations of other models we implemented.\n",
    "\n",
    "Evaluation using recall@k on test set with cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "from gensim.models import doc2vec, word2vec\n",
    "import gensim\n",
    "from collections import namedtuple\n",
    "import timeit\n",
    "import csv\n",
    "\n",
    "from modules.evaluation_metrics import recall_at_k\n",
    "from modules import tfidf\n",
    "from modules import gaussian_naive_bayes\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get data into right format i.e. list of strings\n",
    "train_data = np.append(train.Context.values,train.Utterance.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think we could import the old comment via rs...</td>\n",
       "      <td>basic each xfree86 upload will not forc user t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i 'm not suggest all - onli the one you modifi...</td>\n",
       "      <td>sorri __eou__ i think it be ubuntu relat . __e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon all __eou__ not entir relat to warti...</td>\n",
       "      <td>yep . __eou__ oh , okay . i wonder what happen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interest __eou__ grub-instal work with / be ex...</td>\n",
       "      <td>that the one __eou__</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and becaus python give mark a woodi __eou__ __...</td>\n",
       "      <td>( i think someon be go to make a joke about .a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  i think we could import the old comment via rs...   \n",
       "1  i 'm not suggest all - onli the one you modifi...   \n",
       "2  afternoon all __eou__ not entir relat to warti...   \n",
       "3  interest __eou__ grub-instal work with / be ex...   \n",
       "4  and becaus python give mark a woodi __eou__ __...   \n",
       "\n",
       "                                           Utterance  Label  \n",
       "0  basic each xfree86 upload will not forc user t...      1  \n",
       "1  sorri __eou__ i think it be ubuntu relat . __e...      0  \n",
       "2  yep . __eou__ oh , okay . i wonder what happen...      0  \n",
       "3                               that the one __eou__      1  \n",
       "4  ( i think someon be go to make a joke about .a...      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print train.shape\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18920, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Ground Truth Utterance</th>\n",
       "      <th>Distractor_0</th>\n",
       "      <th>Distractor_1</th>\n",
       "      <th>Distractor_2</th>\n",
       "      <th>Distractor_3</th>\n",
       "      <th>Distractor_4</th>\n",
       "      <th>Distractor_5</th>\n",
       "      <th>Distractor_6</th>\n",
       "      <th>Distractor_7</th>\n",
       "      <th>Distractor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anyon know whi my stock oneir export env var u...</td>\n",
       "      <td>nice thank ! __eou__</td>\n",
       "      <td>wrong channel for it , but check efnet.org , u...</td>\n",
       "      <td>everi time the kernel chang , you will lose vi...</td>\n",
       "      <td>ok __eou__</td>\n",
       "      <td>! nomodeset &gt; acer __eou__ i 'm assum it be a ...</td>\n",
       "      <td>http : //www.ubuntu.com/project/about-ubuntu/d...</td>\n",
       "      <td>thx __eou__ unfortun the program be n't instal...</td>\n",
       "      <td>how can i check ? by do a recoveri for test ? ...</td>\n",
       "      <td>my humbl apolog __eou__</td>\n",
       "      <td># ubuntu-offtop __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i set up my hd such that i have to type a pass...</td>\n",
       "      <td>so you dont know , ok , anyon els ? __eou__ yo...</td>\n",
       "      <td>nmap be nice , but it be n't what i be look fo...</td>\n",
       "      <td>ok __eou__</td>\n",
       "      <td>cdrom work fine on window . __eou__ i dont thi...</td>\n",
       "      <td>ah yes , i have read return as rerun __eou__</td>\n",
       "      <td>hm ? __eou__</td>\n",
       "      <td>not the case , lts be everi other .04 releas ....</td>\n",
       "      <td>pretti much __eou__</td>\n",
       "      <td>i use the one i download from amd __eou__</td>\n",
       "      <td>ffmpeg be part of the packag , quixotedon , at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im tri to use ubuntu on my macbook pro retina ...</td>\n",
       "      <td>just wonder how it run __eou__</td>\n",
       "      <td>yes , that 's what i do , export it to a `` id...</td>\n",
       "      <td>noth - i be talk about the question of myhero ...</td>\n",
       "      <td>that should fix the font be too larg __eou__</td>\n",
       "      <td>okay , so hcitool echo back hci0 &lt; mac address...</td>\n",
       "      <td>i get to the menu with option such as tri ubun...</td>\n",
       "      <td>whi do u need analyz __eou__ it be a toy __eou...</td>\n",
       "      <td>cntrl-c may stop the command but it doe n't fi...</td>\n",
       "      <td>if you re onli go to run ubuntu , just get a n...</td>\n",
       "      <td>the one which be not pick up at the moment be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no suggest ? __eou__ link ? __eou__ how can i ...</td>\n",
       "      <td>you cant load anyth via usb or cd when luk be ...</td>\n",
       "      <td>-p sorri ... __eou__ nmap -p22 __eou__ it doe ...</td>\n",
       "      <td>i guess so i ca n't even launch it . __eou__</td>\n",
       "      <td>note __eou__</td>\n",
       "      <td>rxvt-unicod be one __eou__</td>\n",
       "      <td>i tar all of ~ __eou__</td>\n",
       "      <td>i tar all of ~ __eou__</td>\n",
       "      <td>i do n't realli know if i can help , but i be ...</td>\n",
       "      <td>that work just fine , thank ! __eou__</td>\n",
       "      <td>thank you __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i just ad a second usb printer but not sure wh...</td>\n",
       "      <td>i be set it up under the printer configur __eo...</td>\n",
       "      <td>i 'd say the most common venu would be via lau...</td>\n",
       "      <td>the old hardi man page , http : //manpages.ubu...</td>\n",
       "      <td>i ll give a tri __eou__</td>\n",
       "      <td>by the way , the url you post for davf be from...</td>\n",
       "      <td>http : //ubuntuforums.org/showthread.php ? t=1...</td>\n",
       "      <td>so i load up putti gui , then what do i do ? _...</td>\n",
       "      <td>you should read error messag , it say be you r...</td>\n",
       "      <td>wait the colleg semest to close just to make s...</td>\n",
       "      <td>i be call myself a jerk . all i know be that y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  anyon know whi my stock oneir export env var u...   \n",
       "1  i set up my hd such that i have to type a pass...   \n",
       "2  im tri to use ubuntu on my macbook pro retina ...   \n",
       "3  no suggest ? __eou__ link ? __eou__ how can i ...   \n",
       "4  i just ad a second usb printer but not sure wh...   \n",
       "\n",
       "                              Ground Truth Utterance  \\\n",
       "0                               nice thank ! __eou__   \n",
       "1  so you dont know , ok , anyon els ? __eou__ yo...   \n",
       "2                     just wonder how it run __eou__   \n",
       "3  you cant load anyth via usb or cd when luk be ...   \n",
       "4  i be set it up under the printer configur __eo...   \n",
       "\n",
       "                                        Distractor_0  \\\n",
       "0  wrong channel for it , but check efnet.org , u...   \n",
       "1  nmap be nice , but it be n't what i be look fo...   \n",
       "2  yes , that 's what i do , export it to a `` id...   \n",
       "3  -p sorri ... __eou__ nmap -p22 __eou__ it doe ...   \n",
       "4  i 'd say the most common venu would be via lau...   \n",
       "\n",
       "                                        Distractor_1  \\\n",
       "0  everi time the kernel chang , you will lose vi...   \n",
       "1                                         ok __eou__   \n",
       "2  noth - i be talk about the question of myhero ...   \n",
       "3       i guess so i ca n't even launch it . __eou__   \n",
       "4  the old hardi man page , http : //manpages.ubu...   \n",
       "\n",
       "                                        Distractor_2  \\\n",
       "0                                         ok __eou__   \n",
       "1  cdrom work fine on window . __eou__ i dont thi...   \n",
       "2       that should fix the font be too larg __eou__   \n",
       "3                                       note __eou__   \n",
       "4                            i ll give a tri __eou__   \n",
       "\n",
       "                                        Distractor_3  \\\n",
       "0  ! nomodeset > acer __eou__ i 'm assum it be a ...   \n",
       "1       ah yes , i have read return as rerun __eou__   \n",
       "2  okay , so hcitool echo back hci0 < mac address...   \n",
       "3                         rxvt-unicod be one __eou__   \n",
       "4  by the way , the url you post for davf be from...   \n",
       "\n",
       "                                        Distractor_4  \\\n",
       "0  http : //www.ubuntu.com/project/about-ubuntu/d...   \n",
       "1                                       hm ? __eou__   \n",
       "2  i get to the menu with option such as tri ubun...   \n",
       "3                             i tar all of ~ __eou__   \n",
       "4  http : //ubuntuforums.org/showthread.php ? t=1...   \n",
       "\n",
       "                                        Distractor_5  \\\n",
       "0  thx __eou__ unfortun the program be n't instal...   \n",
       "1  not the case , lts be everi other .04 releas ....   \n",
       "2  whi do u need analyz __eou__ it be a toy __eou...   \n",
       "3                             i tar all of ~ __eou__   \n",
       "4  so i load up putti gui , then what do i do ? _...   \n",
       "\n",
       "                                        Distractor_6  \\\n",
       "0  how can i check ? by do a recoveri for test ? ...   \n",
       "1                                pretti much __eou__   \n",
       "2  cntrl-c may stop the command but it doe n't fi...   \n",
       "3  i do n't realli know if i can help , but i be ...   \n",
       "4  you should read error messag , it say be you r...   \n",
       "\n",
       "                                        Distractor_7  \\\n",
       "0                            my humbl apolog __eou__   \n",
       "1          i use the one i download from amd __eou__   \n",
       "2  if you re onli go to run ubuntu , just get a n...   \n",
       "3              that work just fine , thank ! __eou__   \n",
       "4  wait the colleg semest to close just to make s...   \n",
       "\n",
       "                                        Distractor_8  \n",
       "0                            # ubuntu-offtop __eou__  \n",
       "1  ffmpeg be part of the packag , quixotedon , at...  \n",
       "2  the one which be not pick up at the moment be ...  \n",
       "3                                  thank you __eou__  \n",
       "4  i be call myself a jerk . all i know be that y...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print test.shape\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completely Random Predictor\n",
    "This naive predictor randomly picks one of the responses for each of the rows in the test data set. Therefore, we would expect it to have ~10% accuracy with recall@1, ~20% accuracy with recall@2, ~50% accuracy with recall@5 and 100% accuracy with recall@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Completely random prediction model\n",
    "def random_predictor(context, test):\n",
    "    return np.random.choice(len(test), 10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 1, 10 total choices: 0.0974101\n",
      "Recall @ 2, 10 total choices: 0.195032\n",
      "Recall @ 5, 10 total choices: 0.493869\n",
      "Recall @ 10, 10 total choices: 1\n"
     ]
    }
   ],
   "source": [
    "# As a sanity check, let's see if the random predictor performs as expected\n",
    "y_random = [random_predictor(test.Context[x], test.iloc[x,1:].values) for x in range(len(test))]\n",
    "for k in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ {}, 10 total choices: {:g}\".format(k, recall_at_k(y_random, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random predictor does indeed perform as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Weighting\n",
    "Now let's try to use **TF-IDF** weighting to vectorize the contexts and responses and use **cosine similarity** to compute the rank each of the possible responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit TF-IDF model\n",
    "tfidf_model = tfidf.TFIDF_Predictor()\n",
    "tfidf_model.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 1, 10 total choices: 0.495032\n",
      "Recall @ 2, 10 total choices: 0.596882\n",
      "Recall @ 5, 10 total choices: 0.766121\n",
      "Recall @ 10, 10 total choices: 1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "y = [tfidf_model.predict(test.Context[x], test.iloc[x,1:].values) for x in range(test.shape[0])]\n",
    "for k in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ {}, 10 total choices: {:g}\".format(k, recall_at_k(y, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a basic method, but still a robust one and performs respectably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec\n",
    "Next let's generate word embeddings using word2vec and average the word2vec representations for each word in a message in order to get a feature vector for that message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split each of the messages into lists of words\n",
    "train_data_lists = [m.split() for m in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train w2v model\n",
    "w2v_model = word2vec.Word2Vec(train_data_lists, size=100, min_count=3, iter=3, workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "w2v_model.save('w2v_models/size100_mincount3_iter3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1899.75511289\n"
     ]
    }
   ],
   "source": [
    "# Train w2v model of size 200, min_count 5 and 20 iterations\n",
    "start = timeit.default_timer()\n",
    "w2v_model2 = word2vec.Word2Vec(train_data_lists, size=200, min_count=5, iter=20, workers=4)\n",
    "\n",
    "# Save model\n",
    "w2v_model2.save('w2v_models/size200_mincount5_iter20')\n",
    "stop = timeit.default_timer()\n",
    "print stop - start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load trained w2v model\n",
    "w2v_model = word2vec.Word2Vec.load('w2v_models/size200_mincount5_iter20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_w2v(document, model, num_features):\n",
    "    '''\n",
    "    Calculate a feature vector for a document by averaging the \n",
    "    word2vec representations of its constituent words\n",
    "    \n",
    "    Args:\n",
    "        document: a message as a str\n",
    "        model: trained w2v model\n",
    "        num_features: length of feature vector\n",
    "        \n",
    "    Returns:\n",
    "        Feature vector that is the average of the word2vec representations of all words in the document\n",
    "    '''\n",
    "    # Get vocab of the model\n",
    "    vocab = set(model.index2word)\n",
    "    vector = np.zeros(num_features)\n",
    "    num_words = 0\n",
    "    # Split document into list of words\n",
    "    words = document.split()\n",
    "    \n",
    "    # If word exists in vocabulary, add its w2v to sum\n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            vector = np.add(vector, model[word])\n",
    "            num_words = num_words + 1\n",
    "        \n",
    "    # Average by the number of words\n",
    "    vector = np.divide(vector, num_words)\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def w2v_predict(model, context, responses, size):\n",
    "    '''\n",
    "    Calculates the cosine similarity between the context and each of the possible responses\n",
    "    \n",
    "    Args:\n",
    "        model: a word2vec model\n",
    "        context: a context that we want to find the response for\n",
    "        responses: list of candidate responses containing the actual response\n",
    "        size: size of word2vec vectors for the model\n",
    "        \n",
    "    Returns:\n",
    "        List of response indices sorted in descending order by cosine similarity with context\n",
    "    '''\n",
    "    context_vec = average_w2v(context, model, size)\n",
    "    sims = []\n",
    "    \n",
    "    for response in responses:\n",
    "        # Calculate cosine similarity between the averaged word2vec vector of response and context\n",
    "        response_vec = average_w2v(response, model, size)\n",
    "        sim = cosine_similarity(context_vec.reshape(1, -1), response_vec.reshape(1, -1))[0][0]\n",
    "        sims.append(sim)\n",
    "    \n",
    "    return np.argsort(sims, axis=0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 1, 10 total choices: 0.310307\n",
      "Recall @ 2, 10 total choices: 0.445983\n",
      "Recall @ 5, 10 total choices: 0.70333\n",
      "Recall @ 10, 10 total choices: 1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate w2v averaging model's performance\n",
    "y = [w2v_predict(w2v_model, test.Context[x], test.iloc[x,1:].values, 200) for x in range(len(test))]\n",
    "for k in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ {}, 10 total choices: {:g}\".format(k, recall_at_k(y, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## doc2vec\n",
    "Doc2vec generates vector embeddings for entire documents, so let's use those embeddings as feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taggedMessage = namedtuple('TaggedMessage', 'words tags')\n",
    "documents = []\n",
    "\n",
    "# Preprocess messages\n",
    "for i, message in enumerate(train_data):\n",
    "    # Split into lists of words\n",
    "    words = message.split()\n",
    "    # Add a tag corresponding to the index of the message\n",
    "    tags = [i]\n",
    "    x = taggedMessage(words, tags)\n",
    "    documents.append(taggedMessage(words, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040.17123508\n"
     ]
    }
   ],
   "source": [
    "# Train doc2vec model\n",
    "start = timeit.default_timer()\n",
    "d2v = doc2vec.Doc2Vec(documents, size=100, workers=4, iter=5)\n",
    "stop = timeit.default_timer()\n",
    "print stop - start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d2v.save(\"d2v_size100_iter5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5021.152601\n"
     ]
    }
   ],
   "source": [
    "# Train doc2vec model with different parameters\n",
    "start = timeit.default_timer()\n",
    "d2v2 = doc2vec.Doc2Vec(documents, size=200, workers=4, iter=20)\n",
    "stop = timeit.default_timer()\n",
    "print stop - start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d2v2.save(\"d2v_size200_iter20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d2v_predict(model, context, responses):\n",
    "    '''\n",
    "    Calculates the cosine similarity between the context and each of the possible responses\n",
    "    \n",
    "    Args:\n",
    "        model: a doc2vec model\n",
    "        context: a context that we want to find the response for\n",
    "        responses: list of candidate responses containing the actual response\n",
    "        \n",
    "    Returns:\n",
    "        List of response indices sorted in descending order by cosine similarity with context\n",
    "    '''\n",
    "    context_vector = model.infer_vector(context.split())\n",
    "    sims = []\n",
    "    \n",
    "    for response in responses:\n",
    "        # Calculate cosine similarity between the doc2vec vectors of response and context\n",
    "        response_vector = model.infer_vector(response.split())\n",
    "        sim = cosine_similarity(context_vector.reshape(1, -1), response_vector.reshape(1, -1))[0][0]\n",
    "        sims.append(sim)\n",
    "    \n",
    "    return np.argsort(sims, axis=0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 1, 10 total choices: 0.333245\n",
      "Recall @ 2, 10 total choices: 0.477378\n",
      "Recall @ 5, 10 total choices: 0.737474\n",
      "Recall @ 10, 10 total choices: 1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance with doc2vec model with size 200, 20 iterations\n",
    "y = [d2v_predict(d2v2, test.Context[x], test.iloc[x,1:].values) for x in range(test.shape[0])]\n",
    "for k in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ {}, 10 total choices: {:g}\".format(k, recall_at_k(y, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best doc2vec model performs slightly worse than TF-IDF, though slightly better than word2vec with averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 1, 10 total choices: 0.280391\n",
      "Recall @ 2, 10 total choices: 0.423044\n",
      "Recall @ 5, 10 total choices: 0.70222\n",
      "Recall @ 10, 10 total choices: 1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance with doc2vec model with size 100, 5 iterations\n",
    "y = [d2v_predict(d2v, test.Context[x], test.iloc[x,1:].values) for x in range(test.shape[0])]\n",
    "for k in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ {}, 10 total choices: {:g}\".format(k, recall_at_k(y, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the doc2vec model which took less training time performs more poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export best doc2vec model to tsv\n",
    "Next let's export our best doc2vec model's vectors to tsv for visualization with Google's embedding projector (http://projector.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write a tsv file with one doc2vec per row\n",
    "with open('tsv/doc2vec_first10000.tsv', 'w') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "#     for v in d2v2.docvecs:\n",
    "#         writer.writerow(v)\n",
    "    # Take a subset for now\n",
    "    for i in range(10000):\n",
    "        writer.writerow(d2v2.docvecs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write tsv file with metadata (i.e. all the training text, one per line)\n",
    "with open('tsv/metadata_first10000.tsv', 'w') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "    for doc in train_data[:10000]:\n",
    "        writer.writerow([doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "LDA is a well known topic modelling algorithm from which you can learn the topic distributions of a corpus and infer the topic distribution for a new text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate corpus for use with LDA\n",
    "texts = [doc.split() for doc in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dictionary for corpus\n",
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "# Save dictionary for use later\n",
    "dictionary.save('dict/ubuntu.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create corpus of bag of words\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "gensim.corpora.MmCorpus.serialize('/corpora/ubuntu_bow.mm', corpus)  # store to disk, for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "# Train LDA model\n",
    "lda = gensim.models.ldamulticore.LdaMulticore(corpus, num_topics=100, workers=4)\n",
    "stop = timeit.default_timer()\n",
    "print stop - start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load trained LDA model\n",
    "lda = gensim.models.LdaModel.load(\"LDA/lda_model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load saved dictionary\n",
    "dictionary = gensim.corpora.dictionary.Dictionary.load(\"dict/ubuntu.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lda_feature_vector(topic_dist, num_topics):\n",
    "    '''\n",
    "    Convert gensim LDA topic distribution for a given document to feature vector of length number of topics\n",
    "    \n",
    "    Args:\n",
    "        topic_dist: topic distribution for a message from gensim LDA model\n",
    "                    a list of (topic index, proportion) pairs\n",
    "                    i.e. [(5, 0.59), (12, 0.11)...]\n",
    "        num_topics: total number of topics in the model, for use as length of feature vector\n",
    "            \n",
    "    Returns:\n",
    "        Feature vector for document where the index corresponds to topic number and value is proportion for that topic\n",
    "    '''\n",
    "    vector = np.zeros(num_topics)\n",
    "    \n",
    "    # Fill in values for nonzero topics\n",
    "    for index, value in topic_dist:\n",
    "        vector[index] = value\n",
    "            \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda_predict(model, dictionary, context, responses):\n",
    "    '''\n",
    "    Calculates the cosine similarity between the context and each of the possible responses,\n",
    "    returning a ranked list of responses sorted in decreasing order by cosine similarity\n",
    "    \n",
    "    Args:\n",
    "        model: a lda model\n",
    "        dictionary: dictionary associated with the lda model\n",
    "        context: a context that we want to find the response for\n",
    "        responses: list of candidate responses containing the actual response\n",
    "        \n",
    "    Returns:\n",
    "        List of response indices sorted in descending order by cosine similarity with context\n",
    "    '''\n",
    "    # Infer topic distribution and vectorize\n",
    "    context_vector = get_lda_feature_vector(model[dictionary.doc2bow(context.split())], model.num_topics)\n",
    "    sims = []\n",
    "    \n",
    "    for response in responses:\n",
    "        # Calculate cosine similarity between the lda feature vectors of response and context\n",
    "        response_vector = get_lda_feature_vector(model[dictionary.doc2bow(response.split())], model.num_topics)\n",
    "        sim = cosine_similarity(context_vector.reshape(1, -1), response_vector.reshape(1, -1))[0][0]\n",
    "        sims.append(sim)\n",
    "        \n",
    "    return np.argsort(sims, axis=0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 1, 10 total choices: 0.309\n",
      "Recall @ 2, 10 total choices: 0.451\n",
      "Recall @ 5, 10 total choices: 0.58\n",
      "Recall @ 10, 10 total choices: 1\n",
      "5038.85787487\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance with lda model\n",
    "y = [lda_predict(lda, dictionary, test.Context[x], test.iloc[x,1:].values) for x in range(len(test.shape[0]))]\n",
    "for k in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ {}, 10 total choices: {:g}\".format(k, recall_at_k(y, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA does not perform particularly well, though this may have to do with the parameters with which we trained it. Unfortunately LDA takes a long time to train on this volume of data, so it's difficult to tune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## K-Means Clustering and Naive Bayes\n",
    "Our main custom algorithm focusing on techniques covered in the class. First we cluster the doc2vec vectorizations of each text using minibatch k-means. Then we train a naive bayes classifier using the clustering for class labels. We generate feature vectors for new texts using the posterior probabilities for each cluster based on Naive Bayes. \n",
    "\n",
    "One important note to make is that we use a Gaussian Naive Bayes classifier, as opposed to the multinomial one we implemented in class, since we are dealing with doc2vec embeddings as opposed to bag of words representation. The latter can be modeled with a multinomial distribution since it consists of count data, whereas a Gaussian is a better approximation for the former since we are dealing with continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load trained doc2vec model\n",
    "d2v2 = doc2vec.Doc2Vec.load(\"d2v_models/d2v_size200_iter20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create array of doc2vec vectors\n",
    "X = []\n",
    "for v in d2v2.docvecs:\n",
    "    X.append(v)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cluster messages using minibatch k-means\n",
    "mbkmeans = MiniBatchKMeans(n_clusters=100).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1811, 15893,  4178,   933, 11971, 12963, 26825, 16606, 10324,\n",
       "       16300,  2098,  4099, 31382, 17287, 21533,  6242,  2173, 24888,\n",
       "       10882, 10612,  2593, 10676,  1824, 14499, 24770, 10952,  9274,\n",
       "       19802,  1068, 70106,   681,  9707, 17695, 13869,  7871,  3073,\n",
       "       15131, 11157, 11953, 16035,  7113, 21120,   681, 14956,  3333,\n",
       "       12615,   702, 22298, 22444, 23566,  1169,  8595,  4381, 19173,\n",
       "         779, 16844,  3973, 21909,  2456,  5122, 21109, 20738,  9466,\n",
       "       17923,  1056,  1130, 18391,  3530,  7408, 12595,  3999,  6580,\n",
       "        5839, 13843,  8221,  1314, 17344,   685,  9082,  9658, 18850,\n",
       "         681,   681, 28090,  7782,  6678, 11144, 19752, 31288,  4871,\n",
       "       23209, 16423, 15197, 15355, 11027,   683, 15253,  3947, 14790, 18768], dtype=int32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbkmeans.counts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nb_predict(nb_model, d2v_model, context, responses):\n",
    "    '''\n",
    "    Calculates the cosine similarity between the context and each of the possible responses\n",
    "    \n",
    "    Args:\n",
    "        nb_model: a trained naive bayes classifier\n",
    "        count_vectorizer: a fitted bow vectorizer\n",
    "        context: a context that we want to find the response for\n",
    "        responses: list of candidate responses containing the actual response\n",
    "        \n",
    "    Returns:\n",
    "        List of response indices sorted in descending order by cosine similarity with context\n",
    "    '''\n",
    "    # Get vector of probabilities for each of the clusters for the context\n",
    "    context_vector = nb_model.predict_proba(d2v_model.infer_vector(context.split()).reshape(1, -1))\n",
    "    sims = []\n",
    "    \n",
    "    for response in responses:\n",
    "        # Calculate cosine similarity between the inferred doc2vec vectors of response and context\n",
    "        response_vector = nb_model.predict_proba(d2v_model.infer_vector(response.split()).reshape(1, -1))\n",
    "        sim = cosine_similarity(context_vector, response_vector)[0][0]\n",
    "        sims.append(sim)\n",
    "            \n",
    "    return np.argsort(sims, axis=0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Gaussian naive bayes classifier\n",
    "gaussian_nb = GaussianNB()\n",
    "gaussian_nb.fit(X, mbkmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 1, 10 total choices: 0.161522\n",
      "Recall @ 2, 10 total choices: 0.265803\n",
      "Recall @ 5, 10 total choices: 0.52648\n",
      "Recall @ 10, 10 total choices: 1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance with clustering + gaussian naive bayes approach\n",
    "y = [nb_predict(gaussian_nb, d2v2, test.Context[x], test.iloc[x,1:].values) for x in range(len(test))]\n",
    "for k in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ {}, 10 total choices: {:g}\".format(k, recall_at_k(y, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model unfortunately does not perform particularly well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our own implementation of Gaussian Naive Bayes\n",
    "We made our own implementation of Gaussian Naive Bayes which trained in a reasonable amount of time, demonstrating the speed of training Naive Bayes, even on large datasets like this one. Unfortunately, we ran into some time complexity issues when it came to evaluation, so we weren't able to validate on the full evaluation set. Had we more time, we definitely would have looked into optimizing our implementaion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Format data for use in our implementation of Naive Bayes\n",
    "train_df = pd.DataFrame(X, columns=list(range(X.shape[1])))\n",
    "labels_df = pd.DataFrame(mbkmeans.labels_, columns=[\"labels\"])\n",
    "train_df = pd.concat([labels_df, train_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>-0.134405</td>\n",
       "      <td>-0.085782</td>\n",
       "      <td>0.257740</td>\n",
       "      <td>0.118339</td>\n",
       "      <td>-0.083452</td>\n",
       "      <td>0.081222</td>\n",
       "      <td>0.010578</td>\n",
       "      <td>-0.096038</td>\n",
       "      <td>0.014784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211393</td>\n",
       "      <td>-0.188452</td>\n",
       "      <td>0.166451</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>-0.111762</td>\n",
       "      <td>-0.093503</td>\n",
       "      <td>0.074719</td>\n",
       "      <td>-0.033617</td>\n",
       "      <td>0.075097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0.060166</td>\n",
       "      <td>-0.082015</td>\n",
       "      <td>0.152485</td>\n",
       "      <td>0.130863</td>\n",
       "      <td>-0.067056</td>\n",
       "      <td>0.197265</td>\n",
       "      <td>-0.096574</td>\n",
       "      <td>-0.071066</td>\n",
       "      <td>-0.013178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021187</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>0.034269</td>\n",
       "      <td>-0.057416</td>\n",
       "      <td>-0.029969</td>\n",
       "      <td>-0.067793</td>\n",
       "      <td>-0.168198</td>\n",
       "      <td>0.080696</td>\n",
       "      <td>0.045063</td>\n",
       "      <td>0.027310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>0.077069</td>\n",
       "      <td>0.063212</td>\n",
       "      <td>-0.021065</td>\n",
       "      <td>0.046702</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>-0.003899</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>-0.054937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060134</td>\n",
       "      <td>-0.080793</td>\n",
       "      <td>-0.110839</td>\n",
       "      <td>-0.033480</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>-0.082577</td>\n",
       "      <td>0.075278</td>\n",
       "      <td>-0.061084</td>\n",
       "      <td>-0.060006</td>\n",
       "      <td>-0.084176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>0.178126</td>\n",
       "      <td>-0.049867</td>\n",
       "      <td>0.162412</td>\n",
       "      <td>-0.021864</td>\n",
       "      <td>0.100686</td>\n",
       "      <td>-0.020342</td>\n",
       "      <td>0.024187</td>\n",
       "      <td>0.025997</td>\n",
       "      <td>0.163804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041363</td>\n",
       "      <td>-0.129095</td>\n",
       "      <td>0.149627</td>\n",
       "      <td>-0.086052</td>\n",
       "      <td>-0.054755</td>\n",
       "      <td>-0.100571</td>\n",
       "      <td>0.018280</td>\n",
       "      <td>-0.231799</td>\n",
       "      <td>0.028404</td>\n",
       "      <td>-0.017776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.027928</td>\n",
       "      <td>0.155952</td>\n",
       "      <td>0.017260</td>\n",
       "      <td>0.148459</td>\n",
       "      <td>-0.030822</td>\n",
       "      <td>0.095529</td>\n",
       "      <td>-0.022044</td>\n",
       "      <td>-0.173755</td>\n",
       "      <td>-0.071279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>0.045367</td>\n",
       "      <td>0.040716</td>\n",
       "      <td>-0.040944</td>\n",
       "      <td>-0.026997</td>\n",
       "      <td>0.171865</td>\n",
       "      <td>-0.009010</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>0.034317</td>\n",
       "      <td>0.036460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels         0         1         2         3         4         5  \\\n",
       "0      90 -0.134405 -0.085782  0.257740  0.118339 -0.083452  0.081222   \n",
       "1      49  0.060166 -0.082015  0.152485  0.130863 -0.067056  0.197265   \n",
       "2      90 -0.000282  0.077069  0.063212 -0.021065  0.046702  0.037404   \n",
       "3      94  0.178126 -0.049867  0.162412 -0.021864  0.100686 -0.020342   \n",
       "4      10 -0.027928  0.155952  0.017260  0.148459 -0.030822  0.095529   \n",
       "\n",
       "          6         7         8    ...          190       191       192  \\\n",
       "0  0.010578 -0.096038  0.014784    ...    -0.211393 -0.188452  0.166451   \n",
       "1 -0.096574 -0.071066 -0.013178    ...     0.021187  0.036158  0.034269   \n",
       "2 -0.003899  0.017025 -0.054937    ...    -0.060134 -0.080793 -0.110839   \n",
       "3  0.024187  0.025997  0.163804    ...    -0.041363 -0.129095  0.149627   \n",
       "4 -0.022044 -0.173755 -0.071279    ...     0.011883  0.045367  0.040716   \n",
       "\n",
       "        193       194       195       196       197       198       199  \n",
       "0  0.004803  0.020031 -0.111762 -0.093503  0.074719 -0.033617  0.075097  \n",
       "1 -0.057416 -0.029969 -0.067793 -0.168198  0.080696  0.045063  0.027310  \n",
       "2 -0.033480  0.003020 -0.082577  0.075278 -0.061084 -0.060006 -0.084176  \n",
       "3 -0.086052 -0.054755 -0.100571  0.018280 -0.231799  0.028404 -0.017776  \n",
       "4 -0.040944 -0.026997  0.171865 -0.009010  0.083316  0.034317  0.036460  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN standard deviations found. Filling them in with 1.0 standard deviation instead.\n"
     ]
    }
   ],
   "source": [
    "# Train our implementation of a gaussian naive bayes classifier\n",
    "our_gaussian_nb = gaussian_naive_bayes.GaussianNaiveBayes(train_df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def our_nb_predict(nb_model, d2v_model, context, responses):\n",
    "    '''\n",
    "    Calculates the cosine similarity between the context and each of the possible responses using our implementation of Naive Bayes\n",
    "    \n",
    "    Args:\n",
    "        nb_model: a trained naive bayes classifier\n",
    "        count_vectorizer: a fitted bow vectorizer\n",
    "        context: a context that we want to find the response for\n",
    "        responses: list of candidate responses containing the actual response\n",
    "        \n",
    "    Returns:\n",
    "        List of response indices sorted in descending order by cosine similarity with context\n",
    "    '''\n",
    "    # Get vector of probabilities for each of the clusters for the context\n",
    "    context_vector = nb_model.predict_proba(d2v_model.infer_vector(context.split()))\n",
    "    sims = []\n",
    "    \n",
    "    for response in responses:\n",
    "        # Calculate cosine similarity between the inferred doc2vec vectors of response and context\n",
    "        response_vector = nb_model.predict_proba(d2v_model.infer_vector(response.split()))\n",
    "        sim = cosine_similarity(context_vector.reshape(1,-1), response_vector.reshape(1,-1))[0][0]\n",
    "        sims.append(sim)\n",
    "            \n",
    "    return np.argsort(sims, axis=0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 1, 10 total choices: 0.1\n",
      "Recall @ 2, 10 total choices: 0.2\n",
      "Recall @ 5, 10 total choices: 0.7\n",
      "Recall @ 10, 10 total choices: 1\n",
      "706.754172087\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance with clustering + our implementation of gaussian naive bayes\n",
    "start = timeit.default_timer()\n",
    "y = [our_nb_predict(our_gaussian_nb, d2v2, test.Context[x], test.iloc[x,1:].values) for x in range(10)]\n",
    "for k in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ {}, 10 total choices: {:g}\".format(k, recall_at_k(y, k)))\n",
    "stop = timeit.default_timer()\n",
    "print stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ 1, 10 total choices: 0.21\n",
      "Recall @ 2, 10 total choices: 0.3\n",
      "Recall @ 5, 10 total choices: 0.56\n",
      "Recall @ 10, 10 total choices: 1\n",
      "7050.78050494\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance with clustering + our implementation of gaussian naive bayes\n",
    "start = timeit.default_timer()\n",
    "y = [our_nb_predict(our_gaussian_nb, d2v2, test.Context[x], test.iloc[x,1:].values) for x in range(100)]\n",
    "for k in [1, 2, 5, 10]:\n",
    "    print(\"Recall @ {}, 10 total choices: {:g}\".format(k, recall_at_k(y, k)))\n",
    "stop = timeit.default_timer()\n",
    "print stop - start"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
